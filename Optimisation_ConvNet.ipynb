{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WLhr8r39enXd"
   },
   "source": [
    "## Hyperparameters selection with bayesian optimization (GPU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jyk3v0Pnuu4M"
   },
   "source": [
    "### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 129
    },
    "colab_type": "code",
    "id": "ZFB98eF6ep0D",
    "outputId": "c1e5ccfa-7e4f-4d53-820a-d1d9d66514dc"
   },
   "outputs": [],
   "source": [
    "# Read and save on google drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)\n",
    "import os\n",
    "root_path = 'drive/My Drive/M2/' \n",
    "os.chdir(root_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mKP8Nc9menX-"
   },
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import plot_importance\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import graphviz\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "import sklearn\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tA3lcRxwenYa"
   },
   "outputs": [],
   "source": [
    "# Read data\n",
    "df = pd.read_csv(\"data.csv\")\n",
    "X = df.iloc[:,1:-1]\n",
    "y = np.array(df[\"y\"])\n",
    "y = (y == 1)*1\n",
    "n,d = X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HdzehI9wenb-"
   },
   "outputs": [],
   "source": [
    "# Train/test split \n",
    "X_train, X_test, y_train, y_test = train_test_split(X.values, y, test_size=0.2)\n",
    "\n",
    "scale = StandardScaler()\n",
    "X_train = scale.fit_transform(X_train)\n",
    "X_test = scale.transform(X_test)\n",
    "\n",
    "X_train = torch.from_numpy(X_train).to(torch.float)\n",
    "X_test = torch.from_numpy(X_test).to(torch.float)\n",
    "y_train = torch.from_numpy(y_train).to(torch.float)\n",
    "y_test = torch.from_numpy(y_test).to(torch.float)\n",
    "ntest = y_test.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SLMaWp2wvCmz"
   },
   "source": [
    "### Dataset, dataloader and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4qvTFWa0encH"
   },
   "outputs": [],
   "source": [
    "class EEG_dataset(Dataset):\n",
    "    \n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index,:], self.y[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NdU-6D-8encS"
   },
   "outputs": [],
   "source": [
    "dataset = EEG_dataset(X_train, y_train)\n",
    "dataset_test = EEG_dataset(X_test, y_test)\n",
    "batch_size = 256\n",
    "dataloader = DataLoader(dataset, shuffle=True, batch_size = batch_size)\n",
    "dataloader_test = DataLoader(dataset_test, shuffle=False, batch_size = ntest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "96hfAM40enc9"
   },
   "outputs": [],
   "source": [
    "# Convolution neural net for classification task\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        return x.view(batch_size, -1)\n",
    "    \n",
    "\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, out_channels, inSize = 178, kernel_size=3, stride=1):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        \n",
    "        # convolution + max pooling\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Conv1d(1, out_channels, kernel_size, stride),\n",
    "            nn.MaxPool1d(kernel_size, stride),\n",
    "            nn.Conv1d(out_channels, out_channels*2, kernel_size, stride+1),\n",
    "            nn.MaxPool1d(kernel_size, stride+1),\n",
    "            nn.Conv1d(out_channels*2, out_channels*4, kernel_size, stride+1),\n",
    "            nn.MaxPool1d(kernel_size, stride+1),\n",
    "            nn.AdaptiveMaxPool1d(1), # output of size N x out_channels*4 x 1\n",
    "            Flatten() # for the final linear layer\n",
    "            \n",
    "        )\n",
    "\n",
    "        \n",
    "        size=out_channels*4\n",
    "        self.lin = nn.Linear(size,1)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        conv_flatt = self.main(x)\n",
    "        lin = torch.sigmoid(self.lin(conv_flatt))\n",
    "        return lin.squeeze()\n",
    "    \n",
    "    \n",
    "    def predict(self, xtest):\n",
    "        xtest = xtest.reshape(xtest.shape[0],1,178)\n",
    "        ypred = self.forward(xtest)\n",
    "        ypred = (ypred >= 0.5).to(torch.float)\n",
    "        return ypred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MTnYLlghendG"
   },
   "source": [
    "### Bayesian optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "MzxUs2POeneN",
    "outputId": "834fb1bc-99c0-42f8-8976-9bfa401fe7b7"
   },
   "outputs": [],
   "source": [
    "from hyperopt import fmin, tpe, hp\n",
    "\n",
    "nepochs=200\n",
    "\n",
    "\n",
    "# Input : Hyperparameters to optimize (learning rate and size of convolution)\n",
    "# Output : (- Accuracy)\n",
    "\n",
    "def loss(space):\n",
    "    lr = space['lr']\n",
    "    hlist = space['hlist']\n",
    "    \n",
    "    model = ConvNet(hlist).to(device)\n",
    "    optim = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    loss_fn = nn.BCELoss(reduction = \"mean\")\n",
    "\n",
    "    # 1) Train\n",
    "    for epoch in range(nepochs):\n",
    "        model.train()\n",
    "        for x,y in dataloader:\n",
    "            x = x.reshape(x.shape[0],1,178).to(device) \n",
    "            y = y.to(device)\n",
    "            ypred = model(x)\n",
    "            l = loss_fn(ypred,y)\n",
    "            optim.zero_grad()\n",
    "            l.backward()\n",
    "            optim.step()\n",
    "        \n",
    "    # 2) Test\n",
    "    model.eval()\n",
    "    acc = 0.\n",
    "    for xtest, ytest in dataloader_test:\n",
    "        xtest = xtest.reshape(xtest.shape[0],1,178).to(device)\n",
    "        ytest = ytest.to(device)\n",
    "        ypred = model(xtest)\n",
    "        ypred = (ypred >= 0.5).to(torch.float)\n",
    "        acc += (ypred == ytest).sum().item()\n",
    "    acc /= len(dataset_test)\n",
    "    \n",
    "    return - acc\n",
    "\n",
    "\n",
    "# State space of hyperparameters\n",
    "space = {\n",
    "    'lr': hp.choice(\"lr\", [0.00001, 0.0001, 0.0005, 0.001, 0.002, 0.005, 0.007, 0.0001, 0.0002, 0.0005]),\n",
    "    'hlist': hp.choice(\"hlist\", [10, 15, 20, 25, 30, 35])\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# Return indices of best parameters found\n",
    "n_eval = 10\n",
    "best = fmin(\n",
    "    fn=loss,\n",
    "    space=space,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=n_eval\n",
    ")\n",
    "\n",
    "print(\"Best parameters after {} trials:\".format(n_eval))\n",
    "print(best)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Optimisation_ConvNet.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
